[
    "Even if they are capable of causing catastrophic harms what sort of safeguards would prevent them from causing these?",
    "How do we test safeguard robustness under extreme conditions?",
    "What are the failure modes of current control mechanisms?",
    "How do we design fail-safe systems for AI control?"
]